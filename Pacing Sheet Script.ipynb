{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dependencies\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import pickle\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.base import MIMEBase\n",
    "from email import encoders\n",
    "from datetime import date\n",
    "from pymysql import ProgrammingError\n",
    "from zipfile import *\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "import numpy as np\n",
    "import warnings\n",
    "import io\n",
    "import os\n",
    "import base64\n",
    "import pickle\n",
    "import os.path\n",
    "import mimetypes\n",
    "import boto3\n",
    "from datetime import datetime,timedelta,date\n",
    "import datetime as dt\n",
    "from contextlib import redirect_stdout\n",
    "import requests\n",
    "import zipfile\n",
    "import gspread\n",
    "import json\n",
    "import time\n",
    "import dropbox\n",
    "import sys\n",
    "from pyhive import hive\n",
    "from thrift.transport import THttpClient\n",
    "import re\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_XV7yzXQQfh"
   },
   "source": [
    "### ETV Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LLCTqMYoQQfj"
   },
   "outputs": [],
   "source": [
    "TOKEN = \"dapiae559a9d4c285179a2fc437d2f2a8665\"\n",
    "WORKSPACE_URL = \"dbc-7813cda7-2bd8.cloud.databricks.com\"\n",
    "WORKSPACE_ID = \"0\"\n",
    "CLUSTER_ID = \"0127-180757-quits149\"\n",
    "\n",
    "conn = 'https://%s/sql/protocolv1/o/%s/%s' % (WORKSPACE_URL, WORKSPACE_ID, CLUSTER_ID)\n",
    "\n",
    "transport = THttpClient.THttpClient(conn)\n",
    "\n",
    "auth = \"token:%s\" % TOKEN\n",
    "PY_MAJOR = sys.version_info[0]\n",
    "\n",
    "if PY_MAJOR < 3:\n",
    "  auth = base64.standard_b64encode(auth)\n",
    "else:\n",
    "  auth = base64.standard_b64encode(auth.encode()).decode()\n",
    "\n",
    "transport.setCustomHeaders({\"Authorization\": \"Basic %s\" % auth})\n",
    "\n",
    "cursor = hive.connect(thrift_transport=transport).cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9RolhYqoQQfk"
   },
   "outputs": [],
   "source": [
    "cursor.execute('select date_pst as date, campaign,adgroup,case when adgroup regexp \"_MN\" then \"Managed Networks\" when adgroup regexp \"_AT\" then \"Audience Targeting\" when adgroup regexp \"_RT\" then \"Retargeting\" else \"\" end as tactic_name,case when ad_type=1 then \"Mobile App\" when ad_type=2 then \"Mobile Web\" when ad_type=3 then \"Desktop\" when ad_type=4 then \"CTV\" else \"\" end as device, sum(impressions) as impressions,sum(clicks) as clicks ,sum(complete_view) as complete,sum(cost) as spend  from delta.`s3n://delta-lake-prod/reporting-consolidated/data` where date_pst=date(from_utc_timestamp(current_timestamp(),\"America/Los_Angeles\"))-1 and (campaign like \"%_Video%\" or campaign like \"%_OTT%\" or campaign like \"%_CDV%\") group by 1,2,3,4,5')\n",
    "dd= cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CTvPc9lcQQfk"
   },
   "outputs": [],
   "source": [
    "dfvideo=pd.DataFrame(dd,columns =[\"date\", \"campaign\", \"flight\",\"tactic_name\",\"device\",\"impressions\",\"clicks\",\"complete\",\"spend\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z9Vm0lrkQQfl",
    "outputId": "d169897b-df45-4193-ccb9-da58eb851430"
   },
   "outputs": [],
   "source": [
    "dfvideo['date'] = pd.to_datetime(dfvideo['date']).dt.strftime(\"%m/%d/%y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_a=sqlalchemy.create_engine('mysql+pymysql://extendtv:efHtD9x30@datorama.cluster-cvucgta4ozvp.us-east-1.rds.amazonaws.com:3306/Datorama_Analysis')\n",
    "engine_a.connect().execute(\"DELETE FROM ZMMasterVideo_dlake WHERE DATE =DATE_FORMAT(SUBDATE(CURRENT_DATE(),1),'%%m/%%d/%%y')\")\n",
    "dfvideo.to_sql(name='ZMMasterVideo_dlake', con=engine_a, index=False, if_exists = 'append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYkhzHXqQQfn"
   },
   "outputs": [],
   "source": [
    "cursor.execute('select date_pst as date, campaign,adgroup,case when adgroup regexp \"_MN\" then \"Managed Networks\" when adgroup regexp \"_AT\" then \"Audience Targeting\" when adgroup regexp \"_RT\" then \"Retargeting\" else \"\" end as tactic_name,case when ad_type=1 then \"Mobile App\" when ad_type=2 then \"Mobile Web\" when ad_type=3 then \"Desktop\" when ad_type=4 then \"CTV\" else \"\" end as device, sum(impressions) as impressions,sum(clicks) as clicks ,sum(complete_view) as complete,sum(cost) as spend from delta.`s3n://delta-lake-prod/reporting-consolidated/data` where date_pst=date(from_utc_timestamp(current_timestamp(),\"America/Los_Angeles\"))-1 and (campaign like \"%_Display%\" or campaign like \"%_AUD%\")  group by 1,2,3,4,5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nt9GtNo_QQfo"
   },
   "outputs": [],
   "source": [
    "ds= cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BBpTejGeQQfo"
   },
   "outputs": [],
   "source": [
    "dfdisplay=pd.DataFrame(ds,columns =[\"date\", \"campaign\", \"flight\",\"tactic_name\",\"device\",\"impressions\",\"clicks\",\"complete\",\"spend\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4HARgbv6QQfp",
    "outputId": "799736e5-b78a-4b79-99b7-7262941cbea8"
   },
   "outputs": [],
   "source": [
    "dfdisplay['date'] = pd.to_datetime(dfdisplay['date']).dt.strftime(\"%m/%d/%y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_a=sqlalchemy.create_engine('mysql+pymysql://extendtv:efHtD9x30@datorama.cluster-cvucgta4ozvp.us-east-1.rds.amazonaws.com:3306/Datorama_Analysis')\n",
    "engine_a.connect().execute(\"DELETE FROM ZMMasterDisplay_dlake WHERE DATE =DATE_FORMAT(SUBDATE(CURRENT_DATE(),1),'%%m/%%d/%%y')\")\n",
    "dfdisplay.to_sql(name='ZMMasterDisplay_dlake', con=engine_a, index=False, if_exists = 'append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CBC frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZ9hyL95QQfp"
   },
   "outputs": [],
   "source": [
    "cursor.execute('select campaign,sum(impressions) as impressions,count(DISTINCT ip) as Ip_reach, count(DISTINCT coalesce(concat(ip, device_id), ip, device_id)) as Ip_device_reach from delta.`s3n://delta-lake-prod/reporting-consolidated/data` where impressions >= 1 and year(date_pst)>=2022 and month(date_pst)>=5 and day(date_pst)<>day(current_date()) group by 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DGQO4EjoQQfp"
   },
   "outputs": [],
   "source": [
    "dn= cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zcZn_My3QQfq"
   },
   "outputs": [],
   "source": [
    "freq=pd.DataFrame(dn,columns =[\"campaign\", \"impressions\", \"Ip_reach\",\"Ip_device_reach\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_a=sqlalchemy.create_engine('mysql+pymysql://extendtv:efHtD9x30@datorama.cluster-cvucgta4ozvp.us-east-1.rds.amazonaws.com:3306/Datorama_Analysis')\n",
    "freq.to_sql(name='Camp_Freq', con=engine_a, index=False, if_exists = 'replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_c = sqlalchemy.create_engine('mysql+pymysql://zypmediadataanalyst:0YQrBHKgUp9hLs698smhzYxfGp5Zin@campaigndb.prod.zm.private:3306/extendtv_db')\n",
    "data2=pd.read_sql_query(\"SELECT campaign_name,`status`,date(start_date),frequency_ip_only_reporting FROM ExtendTV_campaign WHERE date(end_date)>=CURRENT_DATE()\", engine_c)\n",
    "data2.to_sql(name='campaignstatus', con=engine_a, index=False, if_exists = 'replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9v8EbLjGQQfr"
   },
   "source": [
    "### BX Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FAybwEtJQQfs"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_cookies(requests_cookiejar, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(requests_cookiejar, f)\n",
    "\n",
    "def load_cookies(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "url = \"https://sinclair.api.beeswax.com/rest/v2/authenticate\"\n",
    "headers = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "payload= {\"email\":\"dharanidharan-c@sbgtv.com\", \"password\":\"dharan@008\", \"keep_logged_in\":'true',\"all_accounts\":\"true\"}\n",
    "response = requests.request(\"POST\", url,json=payload, headers=headers)\n",
    "save_cookies(response.cookies, 'sinclair_buzz_cookie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SCKJCyLoQQfs"
   },
   "outputs": [],
   "source": [
    "today = date.today()\n",
    "url = 'https://sinclair.api.beeswax.com/rest/v2/reporting/run-query'\n",
    "payload= {\n",
    "    \"view\": \"performance_agg\",\n",
    "    \"fields\": [\"account_id\",\"account_name\",\"bid_day\",\"campaign_id\",\"campaign_name\",\"line_item_id\",\"line_item_name\",\"flight_id\",\"impression\",\"clicks\",\"media_spend\",\"spend\",\"vendor_fees\",\"video_completes\",\"line_item_budget_type\"],\n",
    "\"filters\": {\n",
    "    \"account_id_filter\": \">0\",\n",
    "    \"bid_day\":\"yesterday\",\n",
    "        }\n",
    "    }\n",
    "headers = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8WHdSWPQQfs"
   },
   "outputs": [],
   "source": [
    "i=1\n",
    "j=1\n",
    "sleep_secs = 50\n",
    "while i<2:\n",
    "    try:\n",
    "        print(\"Running....\")\n",
    "        g = requests.request(\"POST\", url, json=payload, headers=headers,cookies=load_cookies('sinclair_buzz_cookie'))\n",
    "        a = str(g.text)\n",
    "        link=re.search(\"(?P<url>https?://[^\\s]+)\", a).group(\"url\")\n",
    "        time.sleep(sleep_secs)\n",
    "        o = requests.get(link, cookies=load_cookies('sinclair_buzz_cookie'))\n",
    "        output=o.text\n",
    "        dfbx=pd.read_json(output)\n",
    "        print(\"\\n\\n\\nGot BX data 1 ..\")\n",
    "        i+=1\n",
    "    except Exception as e:\n",
    "        if e is KeyboardInterrupt:\n",
    "            break\n",
    "        print(f\"Failed {j} time\\nRetrying again...\\n\\n\")\n",
    "        j+=1\n",
    "        sleep_secs += 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BzO_EwsOQQft"
   },
   "outputs": [],
   "source": [
    "#renaming column headers\n",
    "dfbx.rename(columns={\n",
    "    'Campaign Name':'campaign',\n",
    "    'Line Item Name':'lineitem',\n",
    "    'Day':'date',\n",
    "    'Clicks':'click',\n",
    "    'Impressions':'imp',\n",
    "    'Video Completes':'vc',\n",
    "    'Spend':'spend',\n",
    "    }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5mOUKXXQQft"
   },
   "outputs": [],
   "source": [
    "dfbx['date'] = pd.to_datetime(dfbx['date']).dt.strftime(\"%m/%d/%y\")\n",
    "dfbx=dfbx[(dfbx['date']!=datetime.today().strftime(\"%m/%d/%y\"))]\n",
    "dfbx['campaign_key']=np.where(dfbx['Account ID']== 5,['LPPcampaign_'+str(dfbx.loc[i,'Campaign ID'])+'_lineitem_'+str(dfbx.loc[i,'Line Item ID'])+'_flight_'+str(dfbx.loc[i,'Flight ID']) for i in dfbx.index],['campaign_'+str(dfbx.loc[i,'Campaign ID'])+'_lineitem_'+str(dfbx.loc[i,'Line Item ID'])+'_flight_'+str(dfbx.loc[i,'Flight ID']) for i in dfbx.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_d=sqlalchemy.create_engine('mysql+pymysql://extendtv:efHtD9x30@datorama.cluster-cvucgta4ozvp.us-east-1.rds.amazonaws.com:3306/Datorama')\n",
    "engine_d.connect().execute(\"DELETE FROM BX_daily WHERE DATE= DATE_FORMAT(SUBDATE(CURRENT_DATE(),1),'%%m/%%d/%%y')\") \n",
    "dfbx.to_sql(name='BX_daily', con=engine_d, index=False, if_exists = 'append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gn4Rh1GFQQfw",
    "outputId": "07ea22e3-e219-4e64-9ee9-1ad1a1f7d543"
   },
   "source": [
    "Device raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i8_J8v1lQQfw"
   },
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"view\": \"platform_agg\",\n",
    "    \"fields\": [\"account_id\",\"account_name\",\"bid_day\",\"campaign_id\",\"campaign_name\",\"line_item_id\",\"line_item_name\",\"flight_id\",\"platform_device_type\",\"impression\"],\n",
    "\"filters\": {\n",
    "        \"bid_day\": \"yesterday\",\n",
    "    \"account_id_filter\": \">0\"\n",
    "    }\n",
    "}\n",
    "headers = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SXxIPE45QQfw"
   },
   "outputs": [],
   "source": [
    "i=1\n",
    "j=1\n",
    "sleep_secs = 50\n",
    "while i<2:\n",
    "    try:\n",
    "        print(\"Running....\")\n",
    "        g = requests.request(\"POST\", url, json=payload, headers=headers,cookies=load_cookies('sinclair_buzz_cookie'))\n",
    "        a = str(g.text)\n",
    "        link=re.search(\"(?P<url>https?://[^\\s]+)\", a).group(\"url\")\n",
    "        time.sleep(sleep_secs)\n",
    "        o = requests.get(link, cookies=load_cookies('sinclair_buzz_cookie'))\n",
    "        output=o.text\n",
    "        dfdv=pd.read_json(output)\n",
    "        print(\"\\n\\n\\nGot BX data 2 ..\")\n",
    "        i+=1\n",
    "    except Exception as e:\n",
    "        if e is KeyboardInterrupt:\n",
    "            break\n",
    "        print(f\"Failed {j} time\\nRetrying again...\\n\\n\")\n",
    "        j+=1\n",
    "        sleep_secs += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vvPvzNmhQQfx"
   },
   "outputs": [],
   "source": [
    "dfdv['Platform Device Type'][dfdv['Platform Device Type'] == 'PC']='Desktop'\n",
    "dfdv['Platform Device Type'][dfdv['Platform Device Type'] == '-1']='Desktop'\n",
    "dfdv['Platform Device Type'][dfdv['Platform Device Type'] == 'TABLET']='MOBILE'\n",
    "dfdv['Platform Device Type'][dfdv['Platform Device Type'] == 'SET_TOP_BOX']='Desktop'\n",
    "dfdv['Platform Device Type'][dfdv['Platform Device Type'] == 'CONNECTED_TV']='Desktop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uYF-izYUQQfx"
   },
   "outputs": [],
   "source": [
    "dfdv['Day'] = pd.to_datetime(dfdv['Day']).dt.strftime(\"%m/%d/%y\")\n",
    "dfdv=dfdv[(dfdv['Day']!=datetime.today().strftime(\"%m/%d/%y\"))]\n",
    "dfdv['campaign_key']=np.where(dfdv['Account ID']== 5,['LPPcampaign_'+str(dfdv.loc[i,'Campaign ID'])+'_lineitem_'+str(dfdv.loc[i,'Line Item ID'])+'_flight_'+str(dfdv.loc[i,'Flight ID']) for i in dfdv.index],['campaign_'+str(dfdv.loc[i,'Campaign ID'])+'_lineitem_'+str(dfdv.loc[i,'Line Item ID'])+'_flight_'+str(dfdv.loc[i,'Flight ID']) for i in dfdv.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ctVyNDsMQQfx",
    "outputId": "43bfdd3c-950e-4310-ff34-f235258ea767"
   },
   "outputs": [],
   "source": [
    "engine_d=sqlalchemy.create_engine('mysql+pymysql://extendtv:efHtD9x30@datorama.cluster-cvucgta4ozvp.us-east-1.rds.amazonaws.com:3306/Datorama')\n",
    "engine_d.connect().execute(\"DELETE FROM BX_device WHERE Day =DATE_FORMAT(SUBDATE(CURRENT_DATE(),1),'%%m/%%d/%%y')\")\n",
    "dfdv.to_sql(name='BX_device', con=engine_d, index=False, if_exists = 'append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Y59jP9NQQfy"
   },
   "source": [
    "### GT Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i6woLRUWQQfy"
   },
   "outputs": [],
   "source": [
    "s3 = boto3.resource(\n",
    "    service_name='s3',\n",
    "    region_name='us-east-2',\n",
    "    aws_access_key_id='AKIAI4IVL3DWGUGDDXKQ',\n",
    "    aws_secret_access_key='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'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "57FvTIYxQQfz"
   },
   "outputs": [],
   "source": [
    "today = str(date.today())\n",
    "filename= \"campaigns\" + \"_\" + today + \".csv\"\n",
    "obj = s3.Bucket('groundtruth-sftp').Object(filename).get()\n",
    "rawdfz = pd.read_csv(obj['Body'], index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qa7H0ujiQQfz"
   },
   "outputs": [],
   "source": [
    "Filtered1 = rawdfz[[\"date\",\"adgroup name\",\"impressions\",\"clicks\",\"spend\",\"total sa\",\"pacing%\"]]\n",
    "Filtered1 = Filtered1[Filtered1['impressions'].notna()]\n",
    "Filtered1 = Filtered1[Filtered1['adgroup name'].notna()]\n",
    "Filtered1['date'] = pd.to_datetime(Filtered1['date']).dt.strftime(\"%m/%d/%y\")\n",
    "Filtered1.spend = [x.strip('$') for x in Filtered1.spend]\n",
    "Filtered1['pacing%'] = [x.strip('%') for x in Filtered1['pacing%']]\n",
    "Filtered1['pacing%']=Filtered1['pacing%'].astype(float)*0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n1UtlwofQQfz"
   },
   "outputs": [],
   "source": [
    "Filtered1.rename(columns={\n",
    "    'date':'Date',\n",
    "    'adgroup name':'Placement',\n",
    "    'impressions':'Impression',\n",
    "    'clicks':'Click',\n",
    "    'spend':'Spend',\n",
    "    'Impressions':'Impressions',\n",
    "    'Clicks':'Clicks',\n",
    "    'total sa':'Total sar',\n",
    "    'pacing%':'Pacing',\n",
    "    }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XF5z9PoYQQfz",
    "outputId": "c00a6811-0501-4615-c6d0-df91c240e46c"
   },
   "outputs": [],
   "source": [
    "s3 = boto3.resource(\n",
    "    service_name='s3',\n",
    "    region_name='us-east-2',\n",
    "    aws_access_key_id='AKIAI4IVL3DWGUGDDXKQ',\n",
    "    aws_secret_access_key='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'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = str(date.today())\n",
    "filename= \"compulse-tenant/campaigns\" + \"_\" + today + \".csv\"\n",
    "obj = s3.Bucket('groundtruth-sftp').Object(filename).get()\n",
    "rawdfc = pd.read_csv(obj['Body'], index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filtered = rawdfc[[\"date\",\"adgroup name\",\"impressions\",\"clicks\",\"spend\",\"total sa\",\"pacing%\"]]\n",
    "Filtered = Filtered[Filtered['impressions'].notna()]\n",
    "Filtered = Filtered[Filtered['adgroup name'].notna()]\n",
    "Filtered['date'] = pd.to_datetime(Filtered['date']).dt.strftime(\"%m/%d/%y\")\n",
    "Filtered.spend = [x.strip('$') for x in Filtered.spend]\n",
    "Filtered['pacing%'] = [x.strip('%') for x in Filtered['pacing%']]\n",
    "Filtered['pacing%']=Filtered['pacing%'].astype(float)*0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filtered.rename(columns={\n",
    "    'date':'Date',\n",
    "    'adgroup name':'Placement',\n",
    "    'impressions':'Impression',\n",
    "    'clicks':'Click',\n",
    "    'spend':'Spend',\n",
    "    'Impressions':'Impressions',\n",
    "    'Clicks':'Clicks',\n",
    "    'total sa':'Total sar',\n",
    "    'pacing%':'Pacing',\n",
    "    }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_a=sqlalchemy.create_engine('mysql+pymysql://extendtv:efHtD9x30@datorama.cluster-cvucgta4ozvp.us-east-1.rds.amazonaws.com:3306/Datorama_Analysis')\n",
    "engine_a.connect().execute(\"DELETE FROM GTRaw_test WHERE DATE =DATE_FORMAT(SUBDATE(CURRENT_DATE(),1),'%%m/%%d/%%y')\") \n",
    "Filtered1.to_sql(name='GTRaw_test', con=engine_a, index=False, if_exists = 'append')\n",
    "Filtered.to_sql(name='GTRaw_test', con=engine_a, index=False, if_exists = 'append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('amazon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['Date','Order','Order ID','Creative','Creative ID','Total cost','Impressions','eCPM','Click-throughs','Video complete']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Date']].apply(pd.to_datetime)\n",
    "df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%m/%d/%y')\n",
    "df=df[(df['Date']!=datetime.today().strftime(\"%m/%d/%y\"))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_a=sqlalchemy.create_engine('mysql+pymysql://extendtv:efHtD9x30@datorama.cluster-cvucgta4ozvp.us-east-1.rds.amazonaws.com:3306/Datorama_Analysis')\n",
    "df.to_sql(name='amazon_raw', con=engine_a, index=False, if_exists = 'replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_df = sheet_instance.get_all_values()\n",
    "note_df = pd.DataFrame.from_dict(note_df)\n",
    "note_df = note_df.replace(r'^\\s*$',np.nan, regex=True)\n",
    "note_df = note_df.rename(columns=note_df.iloc[0])\n",
    "note_df = note_df[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_df['Campaign '].replace(\"\", np.nan, inplace=True)\n",
    "note_df = note_df.dropna(subset=['Campaign '])\n",
    "note_df.rename(columns={\n",
    "    'Date':'date',\n",
    "    'Campaign ':'campaign_name',\n",
    "    'Note':'note'\n",
    "    }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_a=sqlalchemy.create_engine('mysql+pymysql://extendtv:efHtD9x30@datorama.cluster-cvucgta4ozvp.us-east-1.rds.amazonaws.com:3306/Datorama_Analysis')\n",
    "note_df.to_sql(name='note', con=engine_a, index=False, if_exists = 'append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0nOn36TQQf1"
   },
   "source": [
    "### Orders Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dIh2I4arQQf2"
   },
   "outputs": [],
   "source": [
    "#Current month\n",
    "curr_order=\"\"\"select  \n",
    "CASE WHEN i.station_name='Corporate - DS' then 'Datasphere' else j.station_group_name end as `Organization`,\n",
    "case when j.station_group_name in ('1631 Digital','Cumulus Media',\n",
    "'Cunningham',\n",
    "'Euclid Media Group',\n",
    "'Graham Media',\n",
    "'Homebase Digital',\n",
    "'iHeartMedia',\n",
    "'Pikewood Digital',\n",
    "'Univision',\n",
    "'Sinclair Broadcast Group',\n",
    "'CBS',\n",
    "'1797 Creative',\n",
    "'Weigel Broadcast Group',\n",
    "'The Media Beast',\n",
    "'Nulogic Marketing',\n",
    "'Nexstar Digital',\n",
    "'Metro Parent Group',\n",
    "'PMB Media',\n",
    "'NY Interconnect',\n",
    "'Safe Reach',\n",
    "'21st Century Healthcare Consultants',\n",
    "'BuyOTTAds.com',\n",
    "'Lifeboat Creative',\n",
    "'OverTheTop Marketing',\n",
    "'HenkinSchultz',\n",
    "'WFMJ',\n",
    "'Datasphere',\n",
    "'Adams Outdoor',\n",
    "'Homeslice Media',\n",
    "'KDOC',\n",
    "'Estrella Media',\n",
    "'Orange Theory') then 'lic fee' else 'Direct IO' end as `Pricing Type`,\n",
    "b.price_type,\n",
    "i.station_name as `Station`,\n",
    "d.market_name as `Market`,\n",
    "e.advertiser_name as `Advertiser`,\n",
    "b.campaign_name as `Campaign Name`,\n",
    "a.adops_order_id as `IO`,\n",
    "k.media_name as `Media`,\n",
    "m.platform_name as `Platform`,\n",
    "g.accountmanager_name as `AM Team`,\n",
    "l.tactic_name as `Tactic`,\n",
    "b.status as `Status`,\n",
    "n.analyst_name as `Analyst`,b.monthly_flag as `Monthly Flag`,\n",
    "date(b.live_date) as live_date,\n",
    "date(b.end_date) as end_date,\n",
    "b.impressions as `Total goal`,\n",
    "thismonth.impressions as `Month goal`,\n",
    "o.tier_name as `Tier`,\n",
    "b.notes as `Notes`,\n",
    "h.auto_pacing as `Auto Pacing`,\n",
    "z.turbo_redistribution as `Turbo`,b.at_cost_cpm,b.retail_cpm,h.timezone,\n",
    "p.id as product_id\n",
    "from \n",
    "ExtendTV_order a\n",
    "left join ExtendTV_ordercampaign b\n",
    "on a.id=b.order_id\n",
    "left join ExtendTV_market d\n",
    "on a.market_id = d.id\n",
    "left join ExtendTV_advertiser e\n",
    "on a.advertiser_id = e.id\n",
    "left join ExtendTV_accountmanager g\n",
    "on a.accountmanager_id = g.id\n",
    "left join ExtendTV_station i\n",
    "on a.station_id = i.id\n",
    "left join ExtendTV_stationgroup j\n",
    "on i.station_group_id_id = j.id\n",
    "left join ExtendTV_media k\n",
    "on b.media_id = k.id\n",
    "left join ExtendTV_tactic l\n",
    "on b.tactic_id = l.id\n",
    "left join ExtendTV_platform m\n",
    "on b.platform_id = m.id\n",
    "left join ExtendTV_analyst n\n",
    "on b.analyst_id = n.id\n",
    "left join ExtendTV_tier o\n",
    "on b.tier_id = o.id\n",
    "left join extendtv_db.ExtendTV_product p \n",
    "on p.id =b.product_id \n",
    "left join ExtendTV_campaign h\n",
    "on h.campaign_name=b.campaign_name\n",
    "left join ExtendTV_campaignpacing z\n",
    "on z.campaign_id_id=h.id\n",
    "join\n",
    "(select a.id, \n",
    "b.campaign_name,year,month,\n",
    "a.impressions\n",
    " from ExtendTV_campaignmonthlydistribution a\n",
    " left join ExtendTV_ordercampaign b\n",
    " on a.order_campaign_id = b.id\n",
    " where year = year(curdate())\n",
    " and month = month(curdate())\n",
    " group by 1,2,3,4,5) as thismonth\n",
    "on b.campaign_name = thismonth.campaign_name\n",
    "where thismonth.impressions != 0\n",
    "group by 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25;\n",
    "\"\"\"\n",
    "curr_order_raw=pd.read_sql(curr_order,engine_c)\n",
    "curr_order_raw.to_sql(con=engine_a, name='2020curr_order_raw', if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-WfH7ryQQf2"
   },
   "source": [
    "### ETV raw process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Hs86qVJQQf2"
   },
   "outputs": [],
   "source": [
    "#ETV raw data\n",
    "ETV_raw=\"\"\"\n",
    "select campaign,date,\n",
    "sum(CASE WHEN tactic_name = \"Retargeting\" THEN Impressions ELSE 0 END) as `RT_Imps`,\n",
    "sum(CASE WHEN device = \"CTV\" then impressions ELSE 0 END) AS `CTV_Imps`,\n",
    "sum(impressions) as impressions, sum(clicks) as clicks, 0 AS SAR,sum(complete) as completes, sum(spend) as spend,0 as Vendor_Fee,\n",
    "sum(CASE WHEN device = \"Mobile App\" or device = \"Mobile Web\" then impressions ELSE 0 END) as `Mobile_Imps`\n",
    "from ZMMasterVideo_dlake\n",
    "group by 1,2\n",
    "union all\n",
    "select campaign,date,\n",
    "sum(case when tactic_name = \"Retargeting\" THEN Impressions ELSE 0 END) as `RT_Imps`,\n",
    "sum(CASE WHEN device = \"CTV\" then impressions ELSE 0 END) AS `CTV_Imps`,\n",
    "sum(impressions) as impressions, sum(clicks) as clicks,0 AS SAR, 0 as completes, sum(spend) as spend,0 as Vendor_Fee,\n",
    "sum(CASE WHEN device = \"Mobile App\" or device = \"Mobile Web\"  then impressions ELSE 0 END) as `Mobile_Imps`\n",
    "from ZMMasterDisplay_dlake\n",
    "group by 1,2\n",
    "\n",
    "\"\"\"\n",
    "ETV = pd.read_sql(ETV_raw,engine_a)\n",
    "ETV.to_sql(con=engine_a, name='ETV_raw', if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0yZQhPyQQf2"
   },
   "source": [
    "### GT Raw process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ELV7dR-mQQf2"
   },
   "outputs": [],
   "source": [
    "engine_a.connect().execute('insert into GT_Naming select a.Placement as `standardized_campaign`, a.Placement as `raw_campaign` from `GTRaw_test` a left join GT_Naming b on a.Placement = b.raw_campaign where b.raw_campaign is null group by 1,2;')\n",
    "GT_raw=\"\"\"select standardized_campaign as Campaign, DATE as date, \n",
    "0 as `RT_Imps`,\n",
    "0 as `CTV_Imps`,\n",
    "sum(Impression) as impressions,\n",
    "sum(Click) as clicks,\n",
    "SUM(`Total sar`) AS SAR,\n",
    "0 as completes,\n",
    "sum(Spend) as spend,\n",
    "0 as Vendor_Fee,\n",
    "0 as `Mobile_Imps`\n",
    "from GTRaw_test a\n",
    "join\n",
    "GT_Naming b\n",
    "on\n",
    "a.Placement = b.raw_campaign\n",
    "group by 1,2;\"\"\"\n",
    "DX=pd.read_sql(GT_raw,engine_a)\n",
    "DX.to_sql(con=engine_a, name='GT_raw', if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon Raw process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_raw=\"\"\" select `Order` as Campaign, Date as date, \n",
    "0 as `RT_Imps`,\n",
    "0 as `CTV_Imps`,\n",
    "sum(Impressions) as impressions,\n",
    "sum(`Click-throughs`) as clicks,\n",
    "0 AS SAR,\n",
    "sum(`Video complete`) as completes,\n",
    "sum(`Total cost`) as spend,\n",
    "0 as Vendor_Fee,\n",
    "0 as `Mobile_Imps`\n",
    "from amazon_raw \n",
    "group by 1,2;\"\"\"\n",
    "am=pd.read_sql(am_raw,engine_a)\n",
    "am.to_sql(con=engine_a, name='am_raw', if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yccOOgkWQQf2"
   },
   "source": [
    "### BX Raw process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4lO19MBcQQf2"
   },
   "outputs": [],
   "source": [
    "lpp_raw=\"\"\"SELECT campaign_key as campaign ,date,0 AS RT_imp,0 as `CTV_Imps`,sum(imp) as impressions,sum(click) as clicks,0 AS SAR,sum(vc) as completes,SUM(`Media Spend`) as spend, SUM(`Vendor Fees`) AS Vendor_Fee\n",
    "FROM \n",
    "Datorama.BX_daily\n",
    "WHERE `Campaign ID` IN\n",
    "(SELECT DISTINCT SUBSTRING_INDEX(SUBSTRING_INDEX(`Campaign Name`,'_',2),'_',-1) AS id\n",
    "FROM 2020curr_order_raw\n",
    "WHERE `Campaign Name` REGEXP 'LPPcampaign_')\n",
    "GROUP BY 1,2\"\"\"\n",
    "lpp=pd.read_sql(lpp_raw,engine_a)\n",
    "\n",
    "BX_raw=\"\"\"SELECT *\n",
    "FROM \n",
    "Datorama.BX_daily\"\"\"\n",
    "BX=pd.read_sql(BX_raw,engine_a)\n",
    "\n",
    "lppid=\"\"\"SELECT DISTINCT SUBSTRING_INDEX(SUBSTRING_INDEX(`Campaign Name`,'_',2),'_',-1) AS `Campaign ID`\n",
    "FROM 2020curr_order_raw\n",
    "WHERE `Campaign Name` REGEXP 'LPPcampaign_'\"\"\"\n",
    "lppid=pd.read_sql(lppid,engine_a)\n",
    "lppid['Campaign ID']=lppid['Campaign ID'].astype(int) \n",
    "\n",
    "BX['key1'] = 1\n",
    "lppid['key2'] = 1\n",
    "df_1 = pd.merge(BX, lppid, on=['Campaign ID'], how = 'left')\n",
    "df_1 = df_1[~(df_1.key2 == df_1.key1)]\n",
    "df_1 = df_1.drop(['key1','key2'], axis=1)\n",
    "\n",
    "df_1['RT_imp'] = np.where(df_1['lineitem'].str.contains('Retargeting'), df_1['imp'],0)\n",
    "df_1['CTV_Imps']=0\n",
    "df_1['SAR']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-gUbqN1QQf3"
   },
   "outputs": [],
   "source": [
    "df_1.rename(columns={'vc':'completes',\n",
    "                    'imp':'impressions',\n",
    "                    'click':'clicks',\n",
    "                      'Vendor Fees': 'Vendor_Fee'},inplace=True)\n",
    "\n",
    "bx1=df_1.groupby(['campaign','date'],as_index=False)['RT_imp','CTV_Imps','impressions','clicks','SAR','completes','Media Spend','Vendor_Fee'].sum()\n",
    "\n",
    "bx1.rename(columns={'Media Spend':'spend'\n",
    "                 },inplace=True)\n",
    "\n",
    "bx_final = pd.concat([bx1, lpp], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8HbC655HQQf3"
   },
   "source": [
    "BX mob %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ehxQlg8oQQf3"
   },
   "outputs": [],
   "source": [
    "div=\"\"\"SELECT DAY as date,campaign_key as campaign,sum(Impressions) as `Mobile_Imps`\n",
    "FROM Datorama.BX_device\n",
    "WHERE `Platform Device Type` = \"MOBILE\" and \n",
    "`Campaign ID` IN\n",
    "(SELECT DISTINCT SUBSTRING_INDEX(SUBSTRING_INDEX(`Campaign Name`,'_',2),'_',-1) AS id\n",
    "FROM 2020curr_order_raw\n",
    "WHERE `Campaign Name` REGEXP 'LPPcampaign_')\n",
    "GROUP BY 1,2\n",
    "\"\"\"\n",
    "div=pd.read_sql(div,engine_a)\n",
    "\n",
    "mob_raw=\"\"\"SELECT *\n",
    "FROM \n",
    "Datorama.BX_device\n",
    "where `Platform Device Type` = \"MOBILE\" \"\"\"\n",
    "mob_raw=pd.read_sql(mob_raw,engine_a)\n",
    "\n",
    "mob_raw['key1'] = 1\n",
    "df_1 = pd.merge(mob_raw, lppid, on=['Campaign ID'], how = 'left')\n",
    "df_1 = df_1[~(df_1.key2 == df_1.key1)]\n",
    "df_1 = df_1.drop(['key1','key2'], axis=1)\n",
    "\n",
    "bx1=df_1.groupby(['Day','Campaign Name'],as_index=False)['Impressions'].sum()\n",
    "\n",
    "bx1.rename(columns={'Day':'date',\n",
    "                    'Campaign Name':'campaign',\n",
    "                    'Impressions':'Mobile_Imps'\n",
    "                 },inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hy-oqmoZQQf3"
   },
   "outputs": [],
   "source": [
    "div = pd.concat([div, bx1], ignore_index=True, sort=False)\n",
    "bx_update=bx_final.merge(div,on=['campaign','date'],how = 'left')\n",
    "bx_update['Mobile_Imps'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uj2qrni4QQf4"
   },
   "source": [
    "Gro media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jkLW1c5TQQf4"
   },
   "outputs": [],
   "source": [
    "gro=\"\"\"SELECT  \"GRO_Marketing_Monthly_Revenue_2021\" as campaign , \"\" AS `date`, 0 AS RT_imp,0 as `CTV_Imps`,sum(imp) as impressions,sum(click) as clicks,0 AS SAR,sum(vc) as completes,SUM(`Media Spend`) as spend, SUM(`Vendor Fees`) AS Vendor_Fee, 0 as `Mobile_Imps`\n",
    "FROM Datorama.BX_daily\n",
    "WHERE `Account ID`='3'\n",
    "GROUP BY 1,2\"\"\"\n",
    "gro=pd.read_sql(gro,engine_a)\n",
    "\n",
    "bx_update = pd.concat([bx_update, gro], ignore_index=True, sort=False)\n",
    "bx_update.to_sql(con=engine_a, name='BX_raw', if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cR88j0SbQQf4"
   },
   "source": [
    "combined data( ETV+ GT + BX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pidx7quUQQf4"
   },
   "outputs": [],
   "source": [
    "#connection\n",
    "engine_c = sqlalchemy.create_engine('mysql+pymysql://zypmediadataanalyst:0YQrBHKgUp9hLs698smhzYxfGp5Zin@campaigndb.prod.zm.private:3306/extendtv_db')\n",
    "engine_d=sqlalchemy.create_engine('mysql+pymysql://extendtv:efHtD9x30@datorama.cluster-cvucgta4ozvp.us-east-1.rds.amazonaws.com:3306/Datorama')\n",
    "engine_a=sqlalchemy.create_engine('mysql+pymysql://extendtv:efHtD9x30@datorama.cluster-cvucgta4ozvp.us-east-1.rds.amazonaws.com:3306/Datorama_Analysis')\n",
    "\n",
    "#\n",
    "ETV_DX=\"\"\"select * from ETV_raw WHERE SUBSTRING(DATE,1,2) = MONTH(CURRENT_DATE())\n",
    "union all select * from GT_raw WHERE SUBSTRING(DATE,1,2) = MONTH(CURRENT_DATE())\n",
    "union all select * from BX_raw WHERE SUBSTRING(DATE,1,2) = MONTH(CURRENT_DATE())\n",
    "union all select * from am_raw WHERE SUBSTRING(DATE,1,2) = MONTH(CURRENT_DATE())\"\"\"\n",
    "ZMMasterPacing=pd.read_sql(ETV_DX,engine_a)\n",
    "ZMMasterPacing.to_sql(con=engine_a, name='2020ZMMasterPacing', if_exists='replace')\n",
    "\n",
    "campaign_imp_query=\"\"\"select campaign,sum(clicks) as c, sum(Mobile_Imps) as m,sum(RT_Imps) as r,sum(CTV_Imps) as CTV,Sum(SAR) as sar, sum(impressions) as imp,sum(completes) as v,sum(Vendor_Fee) as vendor,sum(spend) as s from `2020ZMMasterPacing` group by 1\"\"\"\n",
    "campaign_imp = pd.read_sql(campaign_imp_query,engine_a)\n",
    "campaign_imp.to_sql(con=engine_a, name='2020campaign_imp', if_exists='replace')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uTDrt_gAQQf4"
   },
   "outputs": [],
   "source": [
    "#L3D\n",
    "L3D=\"\"\"\n",
    "select campaign,\n",
    "sum(case when STR_TO_DATE(`date`, '%m/%d/%Y')=subdate(current_date, 1) then impressions else 0 end) as yesterdayimp,\n",
    "sum(case when STR_TO_DATE(`date`, '%m/%d/%Y') = subdate(current_date, 2) then impressions else 0 end) as twoimp,\n",
    "sum(case when STR_TO_DATE(`date`, '%m/%d/%Y') = subdate(current_date, 3) then impressions else 0 end) as threeimp,\n",
    "sum(case when STR_TO_DATE(`date`, '%m/%d/%Y')=subdate(current_date, 1) then clicks else 0 end) as yesterdayc,\n",
    "sum(case when STR_TO_DATE(`date`, '%m/%d/%Y') = subdate(current_date, 2) then clicks else 0 end) as twoc,\n",
    "sum(case when STR_TO_DATE(`date`, '%m/%d/%Y') = subdate(current_date, 3) then clicks else 0 end) as threec,\n",
    "sum(case when STR_TO_DATE(`date`, '%m/%d/%Y')=subdate(current_date, 1) then completes else 0 end) as yesterdayv,\n",
    "sum(case when STR_TO_DATE(`date`, '%m/%d/%Y') = subdate(current_date, 2) then completes else 0 end) as twov,\n",
    "sum(case when STR_TO_DATE(`date`, '%m/%d/%Y') = subdate(current_date, 3) then completes else 0 end) as threev,\n",
    "sum(case when STR_TO_DATE(`date`, '%m/%d/%Y')=subdate(current_date, 1) then RT_Imps else 0 end) as yesterdayrt,\n",
    "sum(case when STR_TO_DATE(`date`, '%m/%d/%Y') = subdate(current_date, 2) then RT_Imps else 0 end) as twort,\n",
    "sum(case when STR_TO_DATE(`date`, '%m/%d/%Y') = subdate(current_date, 3) then RT_Imps else 0 end) as threert\n",
    "from  `2020ZMMasterPacing` group by 1;\n",
    "\"\"\"\n",
    "L3D=pd.read_sql(L3D,engine_a)\n",
    "L3D.to_sql(con=engine_a, name='2020L3D', if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notes data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sx5Yv0i-QQf4"
   },
   "outputs": [],
   "source": [
    "note_query=\"\"\"select campaign_name,\n",
    "max(case when date='07/01/2022' then note else '' end) as `07/01/2022`,\n",
    "max(case when date='07/02/2022' then note else '' end) as `07/02/2022`,\n",
    "max(case when date='07/03/2022' then note else '' end) as `07/03/2022`,\n",
    "max(case when date='07/04/2022' then note else '' end) as `07/04/2022`,\n",
    "max(case when date='07/06/2022' then note else '' end) as `07/05/2022`,\n",
    "max(case when date='07/06/2022' then note else '' end) as `07/06/2022`,\n",
    "max(case when date='07/07/2022' then note else '' end) as `07/07/2022`,\n",
    "max(case when date='07/08/2022' then note else '' end) as `07/08/2022`,\n",
    "max(case when date='07/09/2022' then note else '' end) as `07/09/2022`,\n",
    "max(case when date='07/10/2022' then note else '' end) as `07/10/2022`,\n",
    "max(case when date='07/11/2022' then note else '' end) as `07/11/2022`,\n",
    "max(case when date='07/12/2022' then note else '' end) as `07/12/2022`,\n",
    "max(case when date='07/13/2022' then note else '' end) as `07/13/2022`,\n",
    "max(case when date='07/14/2022' then note else '' end) as `07/14/2022`,\n",
    "max(case when date='07/15/2022' then note else '' end) as `07/15/2022`,\n",
    "max(case when date='07/16/2022' then note else '' end) as `07/16/2022`,\n",
    "max(case when date='07/17/2022' then note else '' end) as `07/17/2022`,\n",
    "max(case when date='07/18/2022' then note else '' end) as `07/18/2022`,\n",
    "max(case when date='07/19/2022' then note else '' end) as `07/19/2022`,\n",
    "max(case when date='07/20/2022' then note else '' end) as `07/20/2022`,\n",
    "max(case when date='07/21/2022' then note else '' end) as `07/21/2022`,\n",
    "max(case when date='07/22/2022' then note else '' end) as `07/22/2022`,\n",
    "max(case when date='07/23/2022' then note else '' end) as `07/23/2022`,\n",
    "max(case when date='07/24/2022' then note else '' end) as `07/24/2022`,\n",
    "max(case when date='07/25/2022' then note else '' end) as `07/25/2022`,\n",
    "max(case when date='07/26/2022' then note else '' end) as `07/26/2022`,\n",
    "max(case when date='07/27/2022' then note else '' end) as `07/27/2022`,\n",
    "max(case when date='07/28/2022' then note else '' end) as `07/28/2022`,\n",
    "max(case when date='07/29/2022' then note else '' end) as `07/29/2022`,\n",
    "max(case when date='07/30/2022' then note else '' end) as `07/30/2022`,\n",
    "max(case when date='07/31/2022' then note else '' end) as `07/31/2022`\n",
    "from note\n",
    "group by campaign_name;\"\"\"\n",
    "note=pd.read_sql(note_query,engine_a)\n",
    "note.to_sql(con=engine_a, name='2020note_adjusted', if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yNfyrAcCQQf4"
   },
   "outputs": [],
   "source": [
    "#calculate days\n",
    "days_query=\"\"\"select  *,case when `Turbo`=1 then '' else 'Yes' end as `Manual adjusting`,\n",
    "goal.`end_date`-goal.`live_date` as diff,\n",
    "round(DAY(CURDATE()) - DAY(GREATEST(DATE_FORMAT(CURDATE() ,'%Y-%m-01') , goal.`live_date`)),0) as `Days Passed`,\n",
    "round((DAY(LEAST(LAST_DAY(CURDATE()),goal.`end_date`)) - DAY(GREATEST(DATE_FORMAT(CURDATE() ,'%Y-%m-01'), goal.`live_date`)) + 1),0) as `Monthly Days`\n",
    "from `2020curr_order_raw` as goal\"\"\"\n",
    "ZMPacingday=pd.read_sql(days_query,engine_a)\n",
    "ZMPacingday.to_sql(con=engine_a, name='2020ZMPacingday', if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y6702BctQQf5"
   },
   "outputs": [],
   "source": [
    "#Calculate updated goal\n",
    "updated_goal=\"\"\"Select c.`Campaign Name`,`Updated Goal` AS `last month updated`, c.`Month goal`,`pacing imp`,\n",
    "case when c.`Monthly Flag`=0 and `pacing imp`>1.1*`Updated Goal` and c.`Month goal`< `Updated Goal`*0.1 then 0\n",
    "when c.`Monthly Flag`=0 and `pacing imp`>`Updated Goal`*1.1 then c.`Month goal`-`Updated Goal`*0.1\n",
    "when c.`Monthly Flag`=0 and `pacing imp`<`Updated Goal`*1.1 then c.`Month goal`+`Updated Goal`-`pacing imp`\n",
    "when c.`Monthly Flag`=1 and `pacing imp`>`Updated Goal` then c.`Month goal`\n",
    "when c.`Monthly Flag`=1 and `pacing imp`<`Updated Goal` then c.`Month goal`+`Updated Goal`-`pacing imp`\n",
    "else  c.`Month goal` end as `Updated Goal`\n",
    "from 2020curr_order_raw as c left JOIN (SELECT* FROM Billing_save_2021Jan_imp_goal WHERE MonthDate='2022-06-01') as l\n",
    "on c.`Campaign Name`=l.`Campaign Name`\n",
    "WHERE c.`Campaign Name` not REGEXP 'LPPcampaign_'\n",
    "UNION ALL\n",
    "Select c.`Campaign Name`,`Updated Goal` AS `last month updated`, c.`Month goal`,`pacing imp`,\n",
    "case when  `pacing imp`>`Updated Goal` and c.`Month goal`< `Updated Goal`-`pacing imp` then 0\n",
    "when  `pacing imp`>`Updated Goal` then c.`Month goal`-(`pacing imp`-`Updated Goal`)\n",
    "when `pacing imp`<`Updated Goal` then c.`Month goal`+`Updated Goal`-`pacing imp`\n",
    "else  c.`Month goal` end as `Updated Goal`\n",
    "from 2020curr_order_raw as c left JOIN (SELECT* FROM Billing_save_2021Jan_imp_goal WHERE MonthDate='2022-06-01') as l\n",
    "on c.`Campaign Name`=l.`Campaign Name`\n",
    "WHERE c.`Campaign Name` REGEXP 'LPPcampaign_' \"\"\"\n",
    "updated_goal=pd.read_sql(updated_goal,engine_a)\n",
    "updated_goal.to_sql(con=engine_a, name='2021updated_goal', if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s2yh3UDiQQf5"
   },
   "outputs": [],
   "source": [
    "Pacing_query=\"\"\"\n",
    "select z.`Campaign Name`,z.Organization,z.Market,z.Advertiser,`live_date`,`end_date`,z.Timezone,\n",
    "z.Tactic,z.`Status`,z.Analyst,\n",
    "z.`Monthly Flag`,z.Notes,z.`Manual adjusting`,\n",
    "case when z.`Auto pacing`=1 then 'Yes' else '' end as `AutoPacing`,\n",
    "g.`Updated Goal`,round(imp.imp,0) as impression,imp.vendor as Vendor_fee,\n",
    "case when `end_date`>=current_date() then ROUND(`Days Passed`/`Monthly Days`*g.`Updated Goal`,0)  else g.`Updated Goal` end as expected,\n",
    "case when CURDATE() <= z.`end_date` then round(imp.imp/(`Days Passed`/`Monthly Days`*g.`Updated Goal`),2) else round(imp.imp/g.`Updated Goal`,2) end as delta,\n",
    "yesterdayimp as yesterday,\n",
    "twoimp as `two days ago`,\n",
    "threeimp as `three days ago`,\n",
    "round(yesterdayimp/((g.`Updated Goal`-imp.imp)/(`Monthly Days`-`Days Passed`)),2) as `Daily delta`,\n",
    "case when `Days Passed`/`Monthly Days`<=1 and `Days Passed`/`Monthly Days` > 0 then ROUND((`Days Passed`/`Monthly Days`)*100,0)\n",
    "when `Days Passed`/`Monthly Days`<0 or `live_date`=current_date()  then 0 else 100 end as `run time %`,\n",
    "case when g.`Updated Goal`>imp.imp and z.`end_date` >= current_date() then ROUND((g.`Updated Goal`-imp.imp)/(`Monthly Days`-`Days Passed`),0) else 0 end as daily_remaining,\n",
    "ROUND((yesterdayc+twoc+threec)/(yesterdayimp+twoimp+ threeimp)*100,3) as `L3D CTR`,\n",
    "round(imp.c/imp.imp*100,3) as `Monthly CTR`,\n",
    "ROUND((yesterdayv+twov+threev)/(yesterdayimp+twoimp+ threeimp)*100,1) as `L3D VCR`,\n",
    "ROUND((yesterdayv)/(yesterdayimp)*100,1) as `Yesterday VCR`,\n",
    "round(imp.v/imp.imp*100,0) as `Monthly VCR`,\n",
    "round((imp.s)*1000/imp.imp,2) as cpm,\n",
    "ROUND((imp.m/imp.imp)*100,0) as `Mobile %`,\n",
    "ROUND((imp.CTV/imp.imp)*100,0) as `CTV %`,\n",
    "ROUND((yesterdayrt+twort+threert)/(yesterdayimp+twoimp+ threeimp)*100,1) as `L3D RT`,\n",
    "ROUND((imp.r/imp.imp)*100,0) as `RT %`,\n",
    "round(CAST(imp.sar/imp.c as DECIMAL(10,4)),2) as `This Month SAR`,\n",
    "yes.pacing as GTpacing,\n",
    "case \n",
    "when Organization='Lamark Media' and z.`Campaign Name` like '%_OTT_V2%' then 19\n",
    "when Organization='Local Page Pop' and z.`Campaign Name` like '%_OTT_V2%' then 25\n",
    "when Organization='Hyport Digital' and z.`Campaign Name` like '%_OTT_V2%' then 20\n",
    "when Organization='Johnson Media Group' and z.`Campaign Name` like '%_OTT_V2%' then 20\n",
    "when Organization='Tag Team' and z.`Campaign Name` like '%_OTT_V2%' then 20\n",
    "when Organization='Leverage 10' and z.`Campaign Name` like '%_OTT_V2%' and z.price_type=0  then 18.75\n",
    "when Organization='Leverage 10' and z.`Campaign Name` like '%_OTT_V2%' and z.price_type=1  then 20.625\n",
    "when Organization='Today Media' and z.`Campaign Name` like '%_OTT_V2%' and z.product_id=403  then 19\n",
    "when Organization='Today Media' and z.`Campaign Name` like '%_OTT_V2%' and z.product_id=404  then 19\n",
    "when Organization='Today Media' and z.`Campaign Name` like '%_OTT_V2%' and z.product_id=402  then 13\n",
    "when Organization='Today Media' and z.`Campaign Name` like '%_OTT_V2%' and z.price_type=1  then 19\n",
    "when Organization='Dealer Alchemist' and z.`Campaign Name` like '%_CDV%'then 11\n",
    "when Tier='Compulse' then at_cost_cpm\n",
    "when `Pricing Type`='Direct IO' then round(at_cost_cpm*0.6,2)\n",
    "when Organization='Sinclair Broadcast Group' and z.`Campaign Name` like '%_OTT_%'then round(retail_cpm*0.8-3.35,2)\n",
    "when Organization='Univision' and z.`Campaign Name` like '%_OTT_V2%' then 20\n",
    "when Organization='Univision' and Media='Video' then 9.5\n",
    "when Tactic='RT' and Media='Display'then 7\n",
    "else '' end as `cpm limit`,z.`Pricing Type`,z.Tier,\n",
    "z.at_cost_cpm,\n",
    "z.retail_cpm,\n",
    "z.`IO`,\n",
    "z.Media,z.Platform,case when z.Organization='Sinclair Broadcast Group' then 'ml-Corp-Digital-AccountManagers@sbgtv.com'\n",
    "when z.Organization IN ('KDOC') then 'Layla/Heylee'\n",
    "when z.Organization IN ('First Media Services',\"G-Force Global Marketing, LLC\",'MMCC Digital','Synergi Media','Tag Team','Yolo Federal Credit Union','de Novo Marketing','Graham Media','Holdsworth & Nicholas','Big Time Advertising','Dealer Alchemist','Homeslice Media','San Antonio Shoes','Test1') then 'Mark Strother'\n",
    "when z.Organization IN ('Lotus Communications Corp','Today Media','Local Page Pop','WFMJ') then 'Chas Ortman'\n",
    "when z.Organization IN ('Estrella Media','Cunningham','de Novo Marketing') then 'Jesse Wilson'\n",
    "when z.Organization IN ('Cox','Lamark Media','Hyport Digital') then 'Dorothea Bare'\n",
    "when z.Organization IN ('Nulogic Marketing','Chrispy Media','Insured Dealer Services','Johnson Media Group','QBALL digital') then 'Paige Wilder'\n",
    "when z.Organization IN ('Univision') then 'Mark/Chas'\n",
    "else z.`AM Team` end as `AM Team`,\n",
    "z.Station,\n",
    "n.*\n",
    "from `2020ZMPacingday` as z left join `2020L3D` as l\n",
    "on l.campaign=z.`Campaign Name`\n",
    "left join `2020campaign_imp` as imp\n",
    "on imp.campaign=z.`Campaign Name`\n",
    "left join `2020note_adjusted` n\n",
    "on n.campaign_name=z.`Campaign Name`\n",
    "left join `2021updated_goal` as g\n",
    "on z.`Campaign Name`=g.`Campaign Name`\n",
    "left join (select Placement, sum(Impression) as Impressions, sum(Click) as Clicks,Pacing\n",
    "FROM `GTRaw_test`\n",
    "WHERE STR_TO_DATE(Date, '%m/%d/%Y') = subdate(current_date, 1)\n",
    "group by 1) as yes\n",
    "on z.`Campaign Name`=yes.Placement\n",
    "\"\"\"\n",
    "pacing_table=pd.read_sql(Pacing_query,engine_a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qiEzZqp6QQf5"
   },
   "outputs": [],
   "source": [
    "pacing_table['impression'] = pacing_table['impression'].replace(np.nan, 0)\n",
    "pacing_table['Updated Goal'][pacing_table['Updated Goal'] < 0]='0'\n",
    "pacing_table['expected'][pacing_table['expected'] < 0]='0'\n",
    "pacing_table['expected'] = pacing_table['expected'].fillna(0)\n",
    "pacing_table['Updated Goal'] = pacing_table['Updated Goal'].fillna(0)\n",
    "pacing_table = pacing_table.astype({\"expected\": int, \"Updated Goal\": int})\n",
    "pacing_table['last update']=str(date.today())\n",
    "pacing_table1=pacing_table[pacing_table['Tier'].isin([\"Compulse\"])]\n",
    "pacing_table2=pacing_table[~pacing_table['Tier'].isin([\"Compulse\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eVlj2h1hQQf5"
   },
   "outputs": [],
   "source": [
    "# pacing_table2.to_sql(con=engine_a, name='ZM Pacing Tracking Test', if_exists='replace')\n",
    "pacing_table.to_sql(con=engine_a, name='ZM Pacing Tracking Test', if_exists='replace')\n",
    "pacing_table.to_sql(con=engine_a, name='ZM_Pacing_Tracking_Test', if_exists='replace')\n",
    "pacing_table1.to_sql(con=engine_a, name='ZM_Pacing_Tracking_compulse', if_exists='replace')\n",
    "\n",
    "today = str(date.today())\n",
    "filename=\"Pacing\" + \"_\" + today + \".xlsx\"\n",
    "\n",
    "pacing = pd.read_sql_query(\"select* from `ZM Pacing Tracking Test`\", engine_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XxybeuYrQQf5"
   },
   "outputs": [],
   "source": [
    "#creating excel writer object\n",
    "writer = pd.ExcelWriter(filename, engine='xlsxwriter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xxnf2znrQQf5"
   },
   "outputs": [],
   "source": [
    "pacing.to_excel(writer, sheet_name='Sheet1', startrow=1, header=False, index=False)\n",
    "workbook = writer.book\n",
    "worksheet = writer.sheets['Sheet1']\n",
    "(max_row, max_col) = pacing.shape\n",
    "column_settings = []\n",
    "\n",
    "for header in pacing.columns:\n",
    "    column_settings.append({'header': header})\n",
    "    \n",
    "new=worksheet.add_table(0, 0, max_row, max_col - 1, {'columns': column_settings})\n",
    "\n",
    "#saving copy in path\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#media spent daily\n",
    "media_spent=\"\"\"\n",
    "SELECT case when COALESCE(Organization,`Account Name`)='Compulse' then 'Sinclair Broadcast Group' else COALESCE(Organization,`Account Name`) end AS ORG,platform,campaign,Market,Station ,SUM(imp) AS imp, SUM(spend) AS spend,SUM(Vendor_fee) AS Vendor_fee\n",
    "FROM\n",
    "(SELECT `Account Name`,Organization,\"BX\" AS platform,campaign,Market,Station,SUM(imp) AS imp, SUM(`Media Spend`) AS spend,SUM(`Vendor Fees`) AS Vendor_fee\n",
    "FROM Datorama.BX_daily a LEFT JOIN 2020curr_order_raw b ON a.campaign=b.`Campaign Name`\n",
    "WHERE `Account ID` NOT IN(1,2,4)\n",
    "group BY 1,2,3,4,5,6) AS t \n",
    "group BY 1,2,3,4,5\n",
    "union all\n",
    "SELECT case when a.campaign LIKE '%Sweeps%' then \"Sweeps\"\n",
    "when Organization IS NULL then \"Incorrect serving\"\n",
    "ELSE Organization END AS ORG,\"ETV\" as platform,`Campaign Name`,Market,Station,SUM(impressions) AS imp,SUM(spend) AS spend, 0 as Vendor_fee\n",
    "FROM ETV_raw a LEFT JOIN 2020curr_order_raw b ON a.campaign=b.`Campaign Name`\n",
    "group BY 1,2,3,4,5\n",
    "union all\n",
    "SELECT case when a.campaign LIKE '%Sweeps%' then \"Sweeps\"\n",
    "when Organization IS NULL then \"Incorrect serving\"\n",
    "ELSE Organization END AS ORG,\"GT\" as platform,`Campaign Name`,Market,Station,SUM(impressions) AS imp,SUM(spend) AS spend, 0 as Vendor_fee\n",
    "FROM GT_raw a LEFT JOIN 2020curr_order_raw b ON a.campaign=b.`Campaign Name`\n",
    "group BY 1,2,3,4,5\n",
    "union all\n",
    "select Organization AS ORG,\"Eltoro\" as platform,`Campaign Name`,Market,Station,SUM(imps) AS imp,\n",
    "sum(case when insertion_order LIKE '%Display%' then imps*14/1000 ELSE imps*24/1000 END) AS spend, 0 as Vendor_fee\n",
    "FROM Eltoro_Raw a LEFT JOIN 2020curr_order_raw b ON left(insertion_order,length(insertion_order)-10)=b.`Campaign Name`\n",
    "WHERE month(DAY)=MONTH(CURRENT_DATE) AND YEAR(DAY)=YEAR(CURRENT_DATE)\n",
    "group BY 1,2,3,4,5\"\"\"\n",
    "\n",
    "media_table=pd.read_sql(media_spent,engine_a)\n",
    "media_table.to_sql(con=engine_a, name='mediaspend_MTD', if_exists='replace')\n",
    "print(\"SCRIPT ENDED... .. .Now upload the sheet in dropbox\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Pacing updated- updated 12-15.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
